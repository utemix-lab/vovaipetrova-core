---
title: RAG Evaluation
slug: rag-evaluation
summary: Метрики, пороги и процесс оценки качества RAG.
status: draft
tags: [RAG, metrics]
machine_tags: [rag/evaluation]
---

# Как мы меряем RAG

## Обзор

Этот документ описывает метрики, пороги и процесс оценки качества RAG системы в vovaipetrova-core.

## Метрики

### Accuracy@k

**Определение**: Доля вопросов, для которых хотя бы один ожидаемый источник находится в top-k результатах.

**Формула**:
```
Accuracy@k = (количество вопросов с найденным источником) / (общее количество вопросов)
```

**Порог**: ≥ 0.7 (70% вопросов должны находить правильные источники)

**Использование**: Основная метрика для оценки общей эффективности поиска.

### MRR (Mean Reciprocal Rank)

**Определение**: Среднее обратное ранга первого релевантного результата.

**Формула**:
```
MRR = (1/N) * Σ(1/rank_i)
где rank_i — позиция первого релевантного результата для вопроса i
```

**Порог**: ≥ 0.5

**Использование**: Показывает, насколько быстро система находит релевантные результаты.

### nDCG@k (Normalized Discounted Cumulative Gain)

**Определение**: Нормализованная дисконтированная кумулятивная выгода.

**Формула**:
```
DCG@k = Σ(relevance_i / log2(i + 1))
nDCG@k = DCG@k / IDCG@k
где IDCG@k — идеальный DCG (все релевантные документы в начале)
```

**Порог**: ≥ 0.6

**Использование**: Учитывает порядок результатов и релевантность.

## Golden Set

### Структура

Golden Set — это набор контрольных вопросов с ожидаемыми источниками:

```json
{
  "id": "golden-001",
  "question": "Что такое автолинкинг?",
  "expected_ids": ["autolink"],
  "notes": "source_type=kb; explanation=прямой вопрос о термине KB"
}
```

### Расположение

- Файл: `data/rag/golden_set.jsonl`
- Схема: `docs/data-schemas/golden_set.schema.json`

### Требования

- 50–100 вопросов
- Покрытие KB и Stories
- Разнообразие типов вопросов (прямые, детальные, связанные)

## Overrides (blacklist/boost)

Overrides позволяют вручную исключать или усиливать спорные источники при оценке:

```json
{
  "version": "1.0",
  "blacklist": [{ "id": "slice_id_to_skip", "reason": "неактуальный фрагмент" }],
  "boost": [{ "id": "slice_id_to_boost", "weight": 1.5, "reason": "ключевой источник" }]
}
```

- Файл: `data/rag/overrides.json`
- `blacklist` исключает slice_id из результатов.
- `boost` умножает score на `weight` (> 1.0).

## Как запускать оценку

### Базовая оценка

```bash
node scripts/rag/eval_retrieval.mjs
```

### С параметрами

```bash
node scripts/rag/eval_retrieval.mjs --k 10 --golden-set data/rag/golden_set.jsonl
```

### E2E отчёт

```bash
node scripts/rag/e2e_report.mjs
```

Отчёт будет сохранён в:
- JSON: `artifacts/rag/e2e_report_YYYY-MM-DD.json`
- HTML: `prototype/rag-e2e-report.html`

### Проверка overrides

```bash
node scripts/rag/retrieve.mjs --test-overrides
```

## Пороги качества

### Минимальные требования

- **Accuracy@5**: ≥ 0.7
- **MRR**: ≥ 0.5
- **nDCG@5**: ≥ 0.6

### Целевые значения

- **Accuracy@5**: ≥ 0.85
- **MRR**: ≥ 0.7
- **nDCG@5**: ≥ 0.75

## Регрессионное тестирование

После каждого обновления эмбеддингов:

1. Запустить `eval_retrieval.mjs`
2. Проверить метрики против порогов
3. Сгенерировать E2E отчёт
4. Проверить регрессии (сравнить с предыдущим отчётом)

## Интеграция с Weekly Audit

E2E отчёт автоматически включается в Weekly Audit:

- Ссылка на HTML отчёт в разделе "RAG"
- Метрики в сводной таблице
- Якорь `#rag` для прямого доступа

## Улучшение метрик

### Если метрики ниже порогов

1. **Проверить качество эмбеддингов**: Запустить `embed.mjs` заново
2. **Обновить golden set**: Добавить больше вопросов
3. **Улучшить нормализацию**: Обновить `tokenize.mjs`
4. **Проверить дубликаты**: Запустить `check-duplicates.mjs`
5. **Настроить оверрайды**: Обновить `overrides.json`

### Если метрики выше целевых

- Можно уменьшить размер эмбеддингов для оптимизации
- Можно увеличить k для более широкого поиска

## Связанные документы

- [RAG Data Pack](rag-data-pack-dokumentaciya.md) — структура данных
- [Indexing Report](INDEXING_REPORT.md) — отчёт об индексации
- [Tokenization](../../scripts/rag/tokenize.mjs) — нормализация текста

---

*Этот документ обновляется по мере развития системы оценки.*
